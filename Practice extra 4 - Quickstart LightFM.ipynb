{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems 2017/18\n",
    "\n",
    "### Practice 8 - Quickstart LightFM\n",
    "\n",
    "##### The following notebook is available at [LightFM Github repo](https://github.com/lyst/lightfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we'll build an implicit feedback recommender using the Movielens 100k dataset (http://grouplens.org/datasets/movielens/100k/).\n",
    "\n",
    "The code behind this example is available as a [Jupyter notebook](https://github.com/lyst/lightfm/tree/master/examples/quickstart/quickstart.ipynb)\n",
    "\n",
    "LightFM includes functions for getting and processing this dataset, so obtaining it is quite easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lightfm.datasets import fetch_movielens\n",
    "\n",
    "data = fetch_movielens(min_rating=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item_feature_labels': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
       "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
       "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object),\n",
       " 'item_features': <1682x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 1682 stored elements in Compressed Sparse Row format>,\n",
       " 'item_labels': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
       "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
       "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object),\n",
       " 'test': <943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
       " \twith 2153 stored elements in COOrdinate format>,\n",
       " 'train': <943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
       " \twith 19048 stored elements in COOrdinate format>}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This downloads the dataset and automatically pre-processes it into sparse matrices suitable for further calculation. In particular, it prepares the sparse user-item matrices, containing positive entries where a user interacted with a product, and zeros otherwise.\n",
    "\n",
    "We have two such matrices, a training and a testing set. Both have around 1000 users and 1700 items. We'll train the model on the train matrix but test it on the test matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 19048 stored elements in COOrdinate format>\n",
      "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 2153 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "print(repr(data['train']))\n",
    "print(repr(data['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to import the model class to fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the WARP (Weighted Approximate-Rank Pairwise) model. WARP is an implicit feedback model: all interactions in the training matrix are treated as positive signals, and products that users did not interact with they implicitly do not like. The goal of the model is to score these implicit positives highly while assigining low scores to implicit negatives.\n",
    "\n",
    "Model training is accomplished via SGD (stochastic gradient descent). This means that for every pass through the data --- an epoch --- the model learns to fit the data more and more closely. We'll run it for 10 epochs in this example. We can also run it on multiple cores, so we'll set that to 2. (The dataset in this example is too small for that to make a difference, but it will matter on bigger datasets.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 448 ms, sys: 4 ms, total: 452 ms\n",
      "Wall time: 284 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f853b7bff60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(loss='warp')\n",
    "%time model.fit(data['train'], epochs=30, num_threads=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! We should now evaluate the model to see how well it's doing. We're most interested in how good the ranking produced by the model is. Precision@k is one suitable metric, expressing the percentage of top k items in the ranking the user has actually interacted with. `lightfm` implements a number of metrics in the `evaluation` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lightfm.evaluation import precision_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll measure precision in both the train and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train precision: 0.39\n",
      "Test precision: 0.05\n"
     ]
    }
   ],
   "source": [
    "print(\"Train precision: %.2f\" % precision_at_k(model, data['train'], k=5).mean())\n",
    "print(\"Test precision: %.2f\" % precision_at_k(model, data['test'], k=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the model fits the train set better than the test set.\n",
    "\n",
    "For an alternative way of judging the model, we can sample a couple of users and get their recommendations. To make predictions for given user, we pass the id of that user and the ids of all products we want predictions for into the `predict` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 3\n",
      "     Known positives:\n",
      "        Contact (1997)\n",
      "        Air Force One (1997)\n",
      "        In & Out (1997)\n",
      "     Recommended:\n",
      "        Air Force One (1997)\n",
      "        Saint, The (1997)\n",
      "        Chasing Amy (1997)\n",
      "User 25\n",
      "     Known positives:\n",
      "        Fargo (1996)\n",
      "        Godfather, The (1972)\n",
      "        L.A. Confidential (1997)\n",
      "     Recommended:\n",
      "        L.A. Confidential (1997)\n",
      "        Fargo (1996)\n",
      "        Titanic (1997)\n",
      "User 450\n",
      "     Known positives:\n",
      "        Event Horizon (1997)\n",
      "        Scream (1996)\n",
      "        Conspiracy Theory (1997)\n",
      "     Recommended:\n",
      "        Air Force One (1997)\n",
      "        Ransom (1996)\n",
      "        Twister (1996)\n"
     ]
    }
   ],
   "source": [
    "def sample_recommendation(model, data, user_ids):\n",
    "    \n",
    "\n",
    "    n_users, n_items = data['train'].shape\n",
    "\n",
    "    for user_id in user_ids:\n",
    "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
    "        \n",
    "        scores = model.predict(user_id, np.arange(n_items))\n",
    "        top_items = data['item_labels'][np.argsort(-scores)]\n",
    "        \n",
    "        print(\"User %s\" % user_id)\n",
    "        print(\"     Known positives:\")\n",
    "        \n",
    "        for x in known_positives[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "\n",
    "        print(\"     Recommended:\")\n",
    "        \n",
    "        for x in top_items[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "        \n",
    "sample_recommendation(model, data, [3, 25, 450]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### To sum up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train precision WARP: 0.43\n",
      "Test precision WARP: 0.05\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.datasets import fetch_movielens\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "# Load the MovieLens 100k dataset. Only five\n",
    "# star ratings are treated as positive.\n",
    "data = fetch_movielens(min_rating=5.0)\n",
    "\n",
    "# Instantiate and train the model\n",
    "model = LightFM(loss='warp')\n",
    "model.fit(data['train'], epochs=30, num_threads=2)\n",
    "\n",
    "# Evaluate the trained model\n",
    "train_precision = precision_at_k(model, data['train'], k=5).mean()\n",
    "test_precision = precision_at_k(model, data['test'], k=5).mean()\n",
    "\n",
    "print(\"Train precision WARP: {:.2f}\".format(train_precision))\n",
    "print(\"Test precision WARP: {:.2f}\".format(test_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train precision BPR: 0.46\n",
      "Test precision BPR: 0.04\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and train the model\n",
    "model = LightFM(loss='bpr')\n",
    "model.fit(data['train'], epochs=30, num_threads=2)\n",
    "\n",
    "# Evaluate the trained model\n",
    "train_precision = precision_at_k(model, data['train'], k=5).mean()\n",
    "test_precision = precision_at_k(model, data['test'], k=5).mean()\n",
    "\n",
    "print(\"Train precision BPR: {:.2f}\".format(train_precision))\n",
    "print(\"Test precision BPR: {:.2f}\".format(test_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
